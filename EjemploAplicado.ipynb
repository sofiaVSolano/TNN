{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88ac0d53",
   "metadata": {},
   "source": [
    "**Ejemplo aplicado: Predicción de consumo eléctrico a corto plazo**\n",
    "\n",
    "Supongamos que queremos predecir el consumo eléctrico de una ciudad en el siguiente intervalo de tiempo (por ejemplo, dentro de una hora), a partir de datos históricos de consumo.\n",
    "\n",
    "Los datos disponibles son una serie temporal:\n",
    "\n",
    "x(t−5),x(t−4),x(t−3),x(t−2),x(t−1),x(t)\n",
    "\n",
    "\n",
    "En donde representan los valores del consumo eléctrico medidos en varios instantes anteriores, es decir, el historial reciente del sistema dentro de una ventana temporal fija, donde el último valor corresponde al dato más reciente y los anteriores a momentos pasados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e70b75c",
   "metadata": {},
   "source": [
    "**¿Por qué este problema aplica para una TNN?**\n",
    "\n",
    "Este problema no puede resolverse correctamente con una red neuronal tradicional porque:\n",
    "\n",
    "- El consumo actual depende del consumo pasado\n",
    "\n",
    "- Existen patrones temporales (horarios, picos, transiciones)\n",
    "\n",
    "- El orden de los datos importa\n",
    "\n",
    "Por lo tanto, se requiere un modelo que capture dependencias temporales, lo cual es precisamente el objetivo de una Temporal Neural Network (TNN).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02325cfe",
   "metadata": {},
   "source": [
    "**Componentes de la TNN en este ejemplo**\n",
    "\n",
    "**- Entradas temporales**\n",
    "\n",
    "La entrada no es un solo valor, sino una secuencia de valores históricos.\n",
    "\n",
    "**- Mecanismo temporal**\n",
    "\n",
    "En este ejemplo se puede usar una TNN basada en ventanas temporales con retardos.\n",
    "\n",
    "\n",
    "**- Retardos temporales:** Incorporan información del pasado.\n",
    "\n",
    "**- Ventana temporal:** Define cuántos pasos atrás mira el modelo.\n",
    "\n",
    "**- Función de activación:** Aprende patrones no lineales.\n",
    "\n",
    "**- Capa de salida:** Predice el consumo futuro.\n",
    "\n",
    "\n",
    "**ENTRENAMIENTO**\n",
    "\n",
    "- Se usa backpropagation estándar\n",
    "\n",
    "- Cada ejemplo de entrenamiento es una ventana temporal\n",
    "\n",
    "- No hay memoria interna, solo memoria explícita\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37d63ab",
   "metadata": {},
   "source": [
    "**Alternativa: Arquitectura con estados internos y memoria dinámica**\n",
    "\n",
    "¿Por qué usarla?\n",
    "\n",
    "Si queremos capturar dependencias a largo plazo (por ejemplo, efectos semanales o estacionales), una ventana fija puede no ser suficiente.\n",
    "\n",
    "Aquí se utiliza una TNN con estado interno recurrente.\n",
    "\n",
    "**- Estado interno:** Almacena información pasada.\n",
    "\n",
    "**- Retroalimentación:** Permite recordar a largo plazo.\n",
    "\n",
    "**- Entrada actual:** Actualiza el estado.\n",
    "\n",
    "**- Salida:** Predicción basada en memoria acumulada.\n",
    "\n",
    "**ENTRENAMIENTO**\n",
    "\n",
    "- La red se desenrolla en el tiempo\n",
    "\n",
    "- Cada paso temporal se trata como una capa\n",
    "\n",
    "- El error se propaga hacia atrás a través de la secuencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3597e1c3",
   "metadata": {},
   "source": [
    "**Conclusión del ejemplo**\n",
    "\n",
    "La predicción de consumo eléctrico es un problema naturalmente temporal, por lo que es adecuado para una TNN.\n",
    "Dependiendo de la complejidad temporal del fenómeno, se puede optar por una arquitectura con retardos temporales o por una arquitectura con estados internos recurrentes."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
